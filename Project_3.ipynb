{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "difficult-building",
   "metadata": {},
   "source": [
    "# Gender Classifier - Project 3\n",
    "**DATA620**\n",
    "<br>\n",
    "**Wilson Ng**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-memory",
   "metadata": {},
   "source": [
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python(or any classifiers you find on the Internet), and any features you can think of, build the best name gender classifier you can.\n",
    "<br>\n",
    "1. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set.\n",
    "2. Then, starting with the example name gender classifier, make incremental improvements.\n",
    "3. Use the dev-test set to check your progress.\n",
    "4. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "<br>\n",
    "\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rural-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk import classify\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "primary-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-davis",
   "metadata": {},
   "source": [
    "Function provided by the book to extract features of the data. In this case, we have the last letter and last two letters of a given name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "taken-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix1': 'k', 'suffix2': 'ek'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gender_features(word):\n",
    "    return {\n",
    "        'suffix1': word[-1:],\n",
    "        'suffix2': word[-2:]\n",
    "    }\n",
    "\n",
    "gender_features('shrek')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-distribution",
   "metadata": {},
   "source": [
    "Splitting out the data into three sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increased-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(name), g) for (name, g) in names]\n",
    "\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-trustee",
   "metadata": {},
   "source": [
    "Testing the classify method based on on gender_features output. So far so good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extraordinary-large",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Ronaldo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accredited-universe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Angelina'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-cassette",
   "metadata": {},
   "source": [
    "Viewing accuracy of the classifier with the test_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "round-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784\n"
     ]
    }
   ],
   "source": [
    "print(classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "diverse-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =     99.4 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     77.3 : 1.0\n",
      "                 suffix2 = 'ia'           female : male   =     39.0 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     34.3 : 1.0\n",
      "                 suffix2 = 'sa'           female : male   =     33.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "magnetic-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When working with large corpora, constructing a single list that contains the features of every instance\n",
    "# can use up a large amount of memory.\n",
    "# In these cases, use the function nltk.classfy.apply_features, which\n",
    "# returns an object that acts like a list but does not store all the feature sets in memory:\n",
    "\n",
    "train_set = classify.apply_features(gender_features, names[500:])\n",
    "test_set = classify.apply_features(gender_features, names[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "transsexual-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what not to do, overfitting\n",
    "\n",
    "letters = [chr(x) for x in range(ord('a'), ord('z') + 1)]\n",
    "\n",
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features['firstletter'] = name[0].lower()\n",
    "    features['lastletter'] = name[-1].lower()\n",
    "    for letter in letters:\n",
    "        features['count(%s)' % letter] = name.lower().count(letter)\n",
    "        features['has(%s)' % letter] = (letter in name.lower())\n",
    "        return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fossil-oxygen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstletter': 'j', 'lastletter': 'n', 'count(a)': 0, 'has(a)': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features2('John')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-driver",
   "metadata": {},
   "source": [
    "From my understanding of the book, we should split the data into three sets like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "permanent-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = names[1500:]\n",
    "devtest_names = names[500:1500]\n",
    "test_names = names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "micro-comparative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775\n"
     ]
    }
   ],
   "source": [
    "# The training set is used to train the model\n",
    "# the dev-test set is used to perform error analysis\n",
    "# the test set serves in our final evaluation of the system\n",
    "\n",
    "train_set = [(gender_features(n), g) for (n, g) in train_names]\n",
    "devtest_set = [(gender_features(n), g) for (n, g) in devtest_names]\n",
    "test_set = [(gender_features(n), g) for (n, g) in test_names]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-optimization",
   "metadata": {},
   "source": [
    "Once an initial set of features has been chosen, a very productive method for refining\n",
    "the feature set is error analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "joined-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the dev-test set, we can generate a list of the errors\n",
    "# that the classifier makes when predicting name genders:\n",
    "\n",
    "errors = []\n",
    "\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "material-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out the print expression to avoid lengthy document on github\n",
    "# for (tags, guess, name) in sorted(errors):\n",
    "#     print('correct=%-8s guess=%-8s name=%-30s' % (tag, guess, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-yorkshire",
   "metadata": {},
   "source": [
    "I also experimented with Scikit-learn, however, the accuracy is not as high compared to following the instructions on the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sized-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-peeing",
   "metadata": {},
   "source": [
    "Scikit-learn works well with dataframes so I'm converting the names data into a dataframe instead of a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "studied-bulletin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perry</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Demetre</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Devin</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reeva</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netti</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Gender\n",
       "0    Perry  female\n",
       "1  Demetre    male\n",
       "2    Devin  female\n",
       "3    Reeva  female\n",
       "4    Netti  female"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df = pd.DataFrame(names, columns=['Name', 'Gender'])\n",
    "\n",
    "names_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-freeze",
   "metadata": {},
   "source": [
    "Getting the last two letters of a given name and adding it to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "genetic-reviewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>last_two_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perry</td>\n",
       "      <td>female</td>\n",
       "      <td>ry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Demetre</td>\n",
       "      <td>male</td>\n",
       "      <td>re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Devin</td>\n",
       "      <td>female</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reeva</td>\n",
       "      <td>female</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netti</td>\n",
       "      <td>female</td>\n",
       "      <td>ti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7939</th>\n",
       "      <td>Marilin</td>\n",
       "      <td>female</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>Lizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7941</th>\n",
       "      <td>Garret</td>\n",
       "      <td>male</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>Brendan</td>\n",
       "      <td>male</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7943</th>\n",
       "      <td>Diane-Marie</td>\n",
       "      <td>female</td>\n",
       "      <td>ie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7944 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Gender last_two_letters\n",
       "0           Perry  female               ry\n",
       "1         Demetre    male               re\n",
       "2           Devin  female               in\n",
       "3           Reeva  female               va\n",
       "4           Netti  female               ti\n",
       "...           ...     ...              ...\n",
       "7939      Marilin  female               in\n",
       "7940     Lizabeth  female               th\n",
       "7941       Garret    male               et\n",
       "7942      Brendan    male               an\n",
       "7943  Diane-Marie  female               ie\n",
       "\n",
       "[7944 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_last_two_letters(name):\n",
    "    return name[-2:]\n",
    "\n",
    "names_df['last_two_letters'] = names_df['Name'].apply(get_last_two_letters)\n",
    "\n",
    "names_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-raising",
   "metadata": {},
   "source": [
    "Using train_test_split to split the data into separate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stuck-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = names_df.Gender\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(names_df['last_two_letters'], y, test_size = 0.30, random_state = 53)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-dayton",
   "metadata": {},
   "source": [
    "Created a count_vectorizer instance and trained on the given features, which are the last two letters of all the names in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "competitive-builder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'ab', 'ac', 'ad', 'ae', 'af', 'ag', 'ah', 'ai', 'ak']\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-envelope",
   "metadata": {},
   "source": [
    "Fitting the classifier with training data set(count_train) and training labels(y_train).\n",
    "<br>\n",
    "Also assessing accuracy score and producing a confusion matrix.\n",
    "<br>\n",
    "The confusing matrix shows that female names were classified correctly for 1330 of them and wrongly for 176 of them.\n",
    "<br>\n",
    "The matrix also shows that male names were classified correctly for 527 of them and wrongly for 351 of them.\n",
    "<br>\n",
    "This might indicate that there were female names to train the data so the correct results might have skewed due to more training data on female names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "stupid-eugene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7806208053691275\n",
      "[[1318  154]\n",
      " [ 369  543]]\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['female', 'male'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-installation",
   "metadata": {},
   "source": [
    "One way to evaluate and improve the accuracy score of our classifier is by tweaking the alpha values.\n",
    "<br>\n",
    "However, I don't see any significant differences between values raning from 0.0 to 1.0 below. I might have implemented this function wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "accepting-tactics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.7793624161073825\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.7793624161073825\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.7793624161073825\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.7793624161073825\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.7793624161073825\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.7793624161073825\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.7806208053691275\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.7806208053691275\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.7806208053691275\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.7806208053691275\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WN/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:512: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0, 1, 0.1)\n",
    "\n",
    "def train_and_predict(alpha):\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "    pred = nb_classifier.predict(count_test)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-florist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
